db:
  enabled: true
  instances: 2
  storage:
    size: 5Gi
    storageClass: longhorn
  resources:
    requests:
      memory: "512Mi"
      cpu: "1"
    limits:
      memory: "1Gi"
      cpu: "2"

litellm:
  fullnameOverride: litellm
  envVars: {
    USE_DDTRACE: "true",
    LITELLM_MODE: "production",
    REDIS_URL: "redis://redis-master.database.svc.cluster.local:6379",
    OLLAMA_MAC_MINI_16G_BASE_URL: "http://10.10.0.229:11434/v1",
  }
  
  # if set, use this secret for the master key; otherwise, autogenerate a new one
  masterkeySecretName: "env-litellm-master-key"
  
  # if set, use this secret key for the master key; otherwise, use the default key
  masterkeySecretKey: "master_key"

  proxy_config:
    general_settings:
      allow_requests_on_db_unavailable: True
    litellm_settings:
      drop_params: True
      cache: True
      cache_params: # set cache params for redis
        type: redis
        namespace: "litellm.caching.caching"
    model_list:
      # At least one model must exist for the proxy to start.
      - model_name: gpt-4o-mini
        litellm_params:
          model: openai/gpt-4o-mini-2024-07-18
        model_info:
          supports_function_calling: true
      - model_name: o3
        litellm_params:
          model: openai/o3-2025-04-16
        model_info:
          supports_function_calling: true
      - model_name: o4-mini
        litellm_params:
          model: openai/o4-mini
        model_info:
          supports_function_calling: true
      - model_name: gpt-4.1
        litellm_params:
          model: openai/gpt-4.1
        model_info:
          supports_function_calling: true
      - model_name: text-embedding-3-small
        litellm_params:
          model: openai/text-embedding-3-small
        model_info:
          mode: embedding

      - model_name: dall-e-3
        litellm_params:
          model: openai/dall-e-3
        model_info:
          mode: image_generation
      - model_name: whisper-1
        litellm_params:
          model: openai/whisper-1
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-mini-audio
        litellm_params:
          model: openai/gpt-4o-mini-audio-preview-2024-12-17
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-transcribe
        litellm_params:
          model: openai/gpt-4o-transcribe
        model_info:
          mode: audio_transcription
      - model_name: gpt-4o-mini-tts
        litellm_params:
          model: openai/gpt-4o-mini-tts
        model_info:
          mode: audio_speech

      - model_name: gemini-2.5-flash-preview
        litellm_params:
          model: gemini/gemini-2.5-flash-preview-05-20
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.5-pro-preview
        litellm_params:
          model: gemini/gemini-2.5-pro-preview-05-06
        model_info:
          supports_function_calling: true
      - model_name: gemini-2.0-flash-lite
        litellm_params:
          model: gemini/gemini-2.0-flash-lite-preview-02-05
        model_info:
          mode: completion
      - model_name: gemini-embedding-exp
        litellm_params:
          model: gemini/gemini-embedding-exp
        model_info:
          mode: embedding
      - model_name: imagen-3.0-generate
        litellm_params:
          model: gemini/imagen-3.0-generate-002
        model_info:
          mode: image_generation

      - model_name: claude-opus-4
        litellm_params:
          model: anthropic/claude-opus-4-20250514
        model_info:
          supports_function_calling: true
      - model_name: claude-sonnet-4
        litellm_params:
          model: anthropic/claude-sonnet-4-20250514
        model_info:
          supports_function_calling: true
      - model_name: claude-3-7-sonnet
        litellm_params:
          model: anthropic/claude-3-7-sonnet-20250219
        model_info:
          supports_function_calling: true
      - model_name: claude-3-5-haiku
        litellm_params:
          model: anthropic/claude-3-5-haiku-20241022
        model_info:
          supports_function_calling: true

      - model_name: qwen-qwq-32b
        litellm_params:
          model: groq/qwen-qwq-32b
        model_info:
          supports_function_calling: true
      - model_name: deepseek-r1-distill-llama-70b
        litellm_params:
          model: groq/deepseek-r1-distill-llama-70b
        model_info:
          supports_function_calling: true
      - model_name: mistral-saba-24b
        litellm_params:
          model: groq/mistral-saba-24b
      - model_name: llama3.1-8b
        litellm_params:
          model: groq/llama-3.1-8b-instant
      
      - model_name: qwen3-235b-a22b
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b
          api_key: os.environ/FIREWORKS_AI_API_KEY
        model_info:
          supports_function_calling: true
      - model_name: llama4-maverick-instruct-basic
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic
          api_key: os.environ/FIREWORKS_AI_API_KEY
        model_info:
          supports_function_calling: true
      - model_name: llama4-scout-instruct-basic
        litellm_params:
          model: fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic
          api_key: os.environ/FIREWORKS_AI_API_KEY
        model_info:
          supports_function_calling: true

      - model_name: deepseek-reasoner
        litellm_params:
          model: deepseek/deepseek-reasoner
          api_key: os.environ/DEEPSEEK_API_KEY
      - model_name: deepseek-coder
        litellm_params:
          model: deepseek/deepseek-coder
          api_key: os.environ/DEEPSEEK_API_KEY
      - model_name: deepseek-chat
        litellm_params:
          model: deepseek/deepseek-chat
          api_key: os.environ/DEEPSEEK_API_KEY

      - model_name: voyage-3-large
        litellm_params:
          model: voyage/voyage-3-large
          api_key: os.environ/VOYAGE_API_KEY
        model_info:
          mode: embedding
      - model_name: voyage-code-3
        litellm_params:
          model: voyage/voyage-code-3
          api_key: os.environ/VOYAGE_API_KEY
        model_info:
          mode: embedding
      - model_name: voyage-3
        litellm_params:
          model: voyage/voyage-3
          api_key: os.environ/VOYAGE_API_KEY
        model_info:
          mode: embedding
      - model_name: voyage-3-lite
        litellm_params:
          model: voyage/voyage-3-lite
          api_key: os.environ/VOYAGE_API_KEY
        model_info:
          mode: embedding

      - model_name: nomic-embed-text
        litellm_params:
          model: openai/nomic-embed-text
          api_base: "os.environ/OLLAMA_MAC_MINI_16G_BASE_URL"
        model_info:
          mode: embedding
          author: SSegning
      - model_name: starcoder2-3b
        litellm_params:
          model: openai/starcoder2:3b
          api_base: "os.environ/OLLAMA_MAC_MINI_16G_BASE_URL"
        model_info:
          author: SSegning

  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 1000m
      memory: 2Gi

  db:
    useExisting: "true"
    endpoint: "postgresql.database.svc.cluster.local"
    secret:
      name: postgres-secrets
    deployStandalone: false

  ingress:
    enabled: true
    className: traefik
    annotations:
      cert-manager.io/cluster-issuer: self-signed-ca
    hosts:
      - host: litellm.home.ssegning
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: litellm.home.ssegning-tls
        hosts:
          - litellm.home.ssegning