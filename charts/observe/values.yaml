global:
  imageRegistry: container-registry.ssegning.com/docker
  security:
    allowInsecureImages: true

db:
  enabled: true
  instances: 1
  storage:
    size: 10Gi
    storageClass: longhorn
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"

sentry:
  images:
    sentry:
      repository: container-registry.ssegning.com/github/getsentry/sentry
    snuba:
      repository: container-registry.ssegning.com/github/getsentry/snuba
    relay:
      repository: container-registry.ssegning.com/github/getsentry/relay
    symbolicator:
      repository: container-registry.ssegning.com/github/getsentry/symbolicator
    vroom:
      repository: container-registry.ssegning.com/github/getsentry/vroom
    uptimeChecker:
      repository: container-registry.ssegning.com/github/getsentry/uptime-checker
  
  snuba:
    cleanup:
      image:
        repository: container-registry.ssegning.com/docker/clickhouse/clickhouse-server
  redis:
    enabled: false
  externalRedis:
    host: "redis-master.database.svc.cluster.local"
  hooks:
    dbCheck:
      image:
        repository: container-registry.ssegning.com/github/subfuzion/netcat
  postgresql:
    enabled: false
  externalPostgresql:
    existingSecret: 'observe-pg-app'
    existingSecretKeys:
      password: password
      username: username
      database: dbname
      port: port
      host: host
  rabbitmq:
    enabled: false
  filestore:
    filesystem:
      persistence:
        storageClass: longhorn
  ingress:
    regexPathStyle: traefik
    ingressClassName: traefik
    hostname: sentry.ssegning.com
    annotations:
      cert-manager.io/cluster-issuer: cert-cloudflare
    tls:
      - secretName: sentry-ssegning-com-tls
        hosts:
          - sentry.ssegning.com
  system:
    url: https://sentry.ssegning.com
    adminEmail: selastlambou@gmail.com
  vroom:
    persistence:
      storageClassName: longhorn
  geodata:
    persistence:
      storageClass: longhorn
  symbolicator:
    api:
      persistence:
        storageClassName: longhorn
  zookeeper:
    persistence:
      storageClass: longhorn
  kafka:
    controller:
      replicaCount: 1
      persistence:
        storageClass: longhorn
  metrics:
    image:
      repository: container-registry.ssegning.com/docker/prom/statsd-exporter
  pgbouncer:
    image:
      repository: container-registry.ssegning.com/docker/bitnami/pgbouncer
  nginx:
    existingServerBlockConfigmap: observe-sentry-nginx # this should normally be calculated, but it's not. Hmm, why?

grafana-alloy:
  alloy:
    extraContainerPorts:
      - name: "otel"
        containerPort: 4317
      - name: "otel-http"
        containerPort: 4318
    configuration: |-
      // ======================= Grafana Alloy ==============================
      logging {
        level  = "info"
        format = "logfmt"
      }

      discovery.kubernetes "pods" {
        role = "pod"
      }

      discovery.kubernetes "nodes" {
        role = "node"
      }

      discovery.kubernetes "services" {
        role = "service"
      }

      discovery.kubernetes "endpoints" {
        role = "endpoints"
      }

      discovery.kubernetes "endpointslices" {
        role = "endpointslice"
      }

      discovery.kubernetes "ingresses" {
        role = "ingress"
      }

      loki.write "default" {
        endpoint {
          url = "http://loki-gateway:80/loki/api/v1/push"
        }
      }

      // ─── Node syslog ───────────────────────────────────────────────────
      // local.file_match discovers files on the local filesystem using glob patterns and the doublestar library. It returns an array of file paths.
      local.file_match "node_logs" {
        path_targets = [{
          // Monitor syslog to scrape node-logs
          __path__  = "/var/log/syslog",
          job       = "node/syslog",
          node_name = sys.env("HOSTNAME"),
          cluster   = "main",
        }]
      }

      // loki.source.file reads log entries from files and forwards them to other loki.* components.
      // You can specify multiple loki.source.file components by giving them different labels.
      loki.source.file "node_logs" {
        targets    = local.file_match.node_logs.targets
        forward_to = [loki.write.default.receiver]
      }

      // ─── Pod/container logs ────────────────────────────────────────────
      // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
      // If no rules are defined, then the input targets are exported as-is.
      discovery.relabel "pod_logs" {
        targets = discovery.kubernetes.pods.targets

        // Label creation - "namespace" field from "__meta_kubernetes_namespace"
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }

        // Label creation - "pod" field from "__meta_kubernetes_pod_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "pod"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "container"
        }

        // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
          action = "replace"
          target_label = "app"
        }

        // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
        // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
        rule {
          source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
          action        = "replace"
          separator     = "/"
          target_label  = "job"
          replacement   = "$1/$2"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
        // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
        rule {
          source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
          action        = "replace"
          separator     = "/"
          target_label  = "__path__"
          replacement   = "/var/log/pods/*$1/*.log"
        }

        // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_id"]
          action        = "replace"
          target_label  = "container_runtime"
          regex         = "^(\\S+):\\/\\/.+$"
          replacement   = "$1"
        }
      }

      // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
      loki.source.kubernetes "pod_logs" {
        targets    = discovery.relabel.pod_logs.output
        forward_to = [loki.process.pod_logs.receiver]
      }

      // loki.process receives log entries from other Loki components, applies one or more processing stages,
      // and forwards the results to the list of receivers in the component's arguments.
      loki.process "pod_logs" {
        stage.static_labels {
            values = {
              cluster = "main",
            }
        }

        forward_to = [loki.write.default.receiver]
      }

      // ─── Cluster events ────────────────────────────────────────────────
      // loki.source.kubernetes_events tails events from the Kubernetes API and converts them
      // into log lines to forward to other Loki components.
      loki.source.kubernetes_events "cluster_events" {
        job_name   = "integrations/kubernetes/eventhandler"
        log_format = "logfmt"
        forward_to = [
          loki.process.cluster_events.receiver,
        ]
      }

      // loki.process receives log entries from other loki components, applies one or more processing stages,
      // and forwards the results to the list of receivers in the component's arguments.
      loki.process "cluster_events" {
        forward_to = [loki.write.default.receiver]

        stage.static_labels {
          values = {
            cluster = "main",
          }
        }

        stage.labels {
          values = {
            kubernetes_cluster_events = "job",
          }
        }
      }

      // ─── OpenTelemetry (OTLP) Gateway ──────────────────────────────────
      otelcol.receiver.otlp "default" {
        http {}

        grpc {}

        output {
          logs    = [otelcol.processor.batch.logs.input]
          metrics = [otelcol.processor.batch.metrics.input]
          traces  = [otelcol.processor.batch.traces.input]
        }
      }

      otelcol.processor.batch "logs"    { output { logs    = [otelcol.exporter.loki.default.input] } }
      otelcol.processor.batch "metrics" { output { metrics = [otelcol.exporter.prometheus.default.input] } }
      otelcol.processor.batch "traces"  { output { traces  = [otelcol.exporter.otlphttp.tempo.input] } }

      otelcol.exporter.loki "default" {
        forward_to = [loki.write.default.receiver]
      }

      otelcol.exporter.prometheus "default" {
        forward_to = [prometheus.remote_write.mimir.receiver]
      }

      otelcol.exporter.otlphttp "tempo" {
        client { endpoint = "tempo-distributor:4318" }
      }

      discovery.relabel "scrape_targets" {
        targets = concat(
          discovery.kubernetes.pods.targets,
        )

        rule {
            source_labels = [
            "__meta_kubernetes_pod_annotation_prometheus_io_scrape",
          ]
            regex   = "true"
            action  = "keep"
        }

        // __metrics_path__ from annotation
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          target_label  = "__metrics_path__"
          regex         = "(.+)"
          action        = "replace"
        }

        // :port from annotation
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_port", "__address__"]
          regex         = "(\\d+);(.+)"
          target_label  = "__address__"
          replacement   = "$2:$1"
          separator     = ";"
          action        = "replace"
        }

        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }
      }

      prometheus.scrape "k8s" {
        targets = discovery.relabel.scrape_targets.output
        forward_to = [ prometheus.remote_write.mimir.receiver ]
      }

      prometheus.remote_write "mimir" {
        endpoint {
          url = "https://mimir-nginx:80/api/v1/push"
        }
      }
  ingress:
    enabled: true
    annotations:
      cert-manager.io/cluster-issuer: self-signed-ca
    hostname: alloy.home.ssegning
    tls: true
  configReloader: 
    enabled: false
    image: 
      repository: bitnamilegacy/configmap-reload